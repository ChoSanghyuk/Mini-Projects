{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from collections import Counter\n",
    "# from collections import defaultdict\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "import math\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = './data/extractive_test_v2.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sentence(article):\n",
    "    article = re.sub('”', ' ', article)\n",
    "#     article = re.sub('  ', ' ', article)\n",
    "#     article = re.sub('[-=+,#/\\?:^$.@*※~&%ㆍ!』\\\\‘|\\[\\]\\<\\>`\\'…》]', '', article)\n",
    "    bracket = re.findall(r'\\([^)]*\\)', article )\n",
    "    for i in bracket:\n",
    "        word = i.strip('()')\n",
    "        if word.isupper():\n",
    "            end_index = article.find(i)\n",
    "            word_len = article[end_index:0:-1].find(' ')\n",
    "            start_index = end_index - word_len +1\n",
    "            origin = article[start_index : end_index]\n",
    "            article = article[:end_index+len(i)] + article[end_index+len(i):].replace(word, origin)\n",
    "        else:\n",
    "            if '이하' in word:\n",
    "                word = word[3:]\n",
    "                n_space = word.count(' ')\n",
    "                end_index = article.find(word)-4\n",
    "                range_candidate = article[end_index-30:end_index].split(' ')[::-1]\n",
    "                origin = ' '.join(range_candidate[:n_space+1][::-1])\n",
    "                article = article[:end_index+len(i)] + article[end_index+len(i):].replace(word, origin)\n",
    "        # 괄호는 다 제거\n",
    "        article = article.replace(i,'')\n",
    "    article = ''.join(re.findall('[ 가-힣a-zA-Z0-9]',  article) )\n",
    "    \n",
    "    return article.strip(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저\n",
    "from konlpy.tag import Komoran\n",
    "\n",
    "komoran = Komoran()\n",
    "def komoran_tokenize(sent):\n",
    "    words = komoran.pos(sent, join=True)\n",
    "    words = [w for w in words if ('/NN' in w or '/XR' in w or '/VA' in w or '/VV' in w)]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scan_vocabulary(sents, tokenize, min_count=2):\n",
    "    temp = Counter(w for sent in sents for w in tokenize(sent))\n",
    "    temp = {w:c for w,c in temp.items() if c >= min_count}\n",
    "    counter = {}\n",
    "    for i in temp.keys():\n",
    "        w = i.split('/')[0]        \n",
    "        if w == '원':\n",
    "            continue\n",
    "        if len(w) == 1 and temp[i] <5 :\n",
    "            continue\n",
    "        counter[i] = temp[i] \n",
    "    idx_to_vocab = [w for w, _ in sorted(counter.items(), key=lambda x:-x[1])]\n",
    "    vocab_to_idx = {vocab:idx for idx, vocab in enumerate(idx_to_vocab)}\n",
    "    return idx_to_vocab, vocab_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pagerank(x, df=0.85, max_iter=30):\n",
    "    assert 0 < df < 1\n",
    "\n",
    "    # initialize\n",
    "    A = normalize(x, axis=0, norm='l1')\n",
    "    R = np.ones(A.shape[0]).reshape(-1,1)\n",
    "    bias = (1 - df) * np.ones(A.shape[0]).reshape(-1,1)\n",
    "    \n",
    "    # iteration\n",
    "    for _ in range(max_iter):\n",
    "        R = df * (A * R) + bias\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_sent_sim(s1, s2):\n",
    "    n1 = len(s1)\n",
    "    n2 = len(s2)\n",
    "    if (n1 <= 1) or (n2 <= 1):\n",
    "        return 0\n",
    "    common = len(set(s1).intersection(set(s2)))\n",
    "    base = math.log(n1) + math.log(n2)\n",
    "    return common / base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_sent_sim(s1, s2):\n",
    "    if (not s1) or (not s2):\n",
    "        return 0\n",
    "\n",
    "    s1 = Counter(s1)\n",
    "    s2 = Counter(s2)\n",
    "    norm1 = math.sqrt(sum(v ** 2 for v in s1.values()))\n",
    "    norm2 = math.sqrt(sum(v ** 2 for v in s2.values()))\n",
    "    prod = 0\n",
    "    for k, v in s1.items():\n",
    "        prod += v * s2.get(k, 0)\n",
    "    return prod / (norm1 * norm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_graph(sents, tokenize, similarity, min_count=2, min_sim=0.1):\n",
    "    _, vocab_to_idx = scan_vocabulary(sents, tokenize, min_count)\n",
    "\n",
    "    tokens = [[w for w in tokenize(sent) if w in vocab_to_idx] for sent in sents]\n",
    "    print(tokens)\n",
    "    rows, cols, data = [], [], []\n",
    "    n_sents = len(tokens)\n",
    "    for i, tokens_i in enumerate(tokens):\n",
    "        for j, tokens_j in enumerate(tokens):\n",
    "            if i >= j:\n",
    "                continue\n",
    "            sim = similarity(tokens_i, tokens_j)\n",
    "            if sim < min_sim:\n",
    "                continue\n",
    "            rows.append(i)\n",
    "            cols.append(j)\n",
    "            data.append(sim)\n",
    "    return csr_matrix((data, (rows, cols)), shape=(n_sents, n_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textrank_keysentence(sents, tokenize, min_count, min_sim, similarity, df=0.85, max_iter=30, topk= 3 ):\n",
    "    g = sent_graph(sents, tokenize,  similarity ,min_count, min_sim )\n",
    "    R = pagerank(g, df, max_iter).reshape(-1)\n",
    "    idxs = R.argsort()[-topk:]\n",
    "    key_index = [ idx for idx in reversed(idxs)]\n",
    "#     keysents = [(idx, R[idx], sents[idx]) for idx in reversed(idxs)]\n",
    "#     summary_3 = '\\n'.join( [sents[idx] for idx in reversed(idxs) ]  )\n",
    "    return key_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2 =  pd.DataFrame( columns = ['id' , 'summary'])\n",
    "# submission2 =  pd.DataFrame( columns = ['id' , 'summary'])\n",
    "# submission3 =  pd.DataFrame( columns = ['id' , 'summary'])\n",
    "# submission4 =  pd.DataFrame( columns = ['id' , 'summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['석문/NNP', '간척지/NNG', '임차/NNG', '법인/NNP', '협의회/NNG', '한국농어촌공사/NNP', '당진/NNP', '지사/NNP', '공공/NNG', '비축/NNG', '벼/NNG', '시위/NNG', '벌이/VV', '있/VV'], ['석문/NNP', '간척지/NNG', '임차/NNG', '법인/NNP', '협의회/NNG', '농림/NNP', '축산/NNP', '식품/NNG', '간척지/NNG', '임대료/NNG', '책정/NNG', '한국농어촌공사/NNP', '당진/NNP', '지사/NNP', '공공/NNG', '비축/NNG', '벼/NNG', '시위/NNG', '벌이/VV'], ['영농/NNG', '조합/NNP', '법인/NNP', '간척지/NNG', '협의회/NNG', '벼/NNG', '시위/NNG', '책정/NNG', '임대료/NNG', '인하/NNG', '있/VV'], ['지나/VV', '농림/NNP', '축산/NNP', '식품/NNG', '임대료/NNG', '올해/NNG', '상황/NNG'], ['임차/NNG', '올해/NNG', '임대료/NNG', '인하/NNG', '지나/VV', '동안/NNG', '보상/NNG', '상황/NNG'], ['간척지/NNG', '협의회/NNG', '기간/NNG', '연장/NNG', '연장/NNG', '기간/NNG', '동안/NNG', '인하/NNG', '임대료/NNG', '지나/VV', '보상/NNG'], ['벼/NNG', '시위/NNG', '임대료/NNG', '벼/NNG'], ['영농/NNG', '조합/NNP', '법인/NNP', '한국농어촌공사/NNP', '있/VV', '상황/NNG'], ['만들/VV', '있/VV', '만들/VV', '있/VV']]\n",
      "[['벌/NNG', '떼/NNG', '해장국/NNP', '손님/NNG', '보답/NNG', '시간/NNP', '영업/NNG', '재개/NNG'], ['특별/XR', '감사/NNG', '이벤트/NNG'], ['동안/NNG', '야간/NNG', '손님/NNG', '위하/VV', '뼈/NNG', '해장국/NNP', '감자탕/NNP', '가격/NNG', '제공/NNG'], ['대표/NNG', '손님/NNG', '감사/NNG', '보답/NNG', '영업/NNG', '재개/NNG', '이벤트/NNG', '마련/NNG'], ['벌/NNG', '떼/NNG', '해장국/NNP', '메뉴/NNP', '뼈/NNG', '해장국/NNP', '감자탕/NNP', '이다/NNP'], ['사용/NNG', '뼈/NNG'], ['뼈/NNG', '시간/NNP', '동안/NNG', '사용/NNG'], ['양파/NNP', '양파/NNP', '대파/NNG', '들어가/VV'], ['더하/VV'], ['대파/NNG', '뼈/NNG', '해장국/NNP'], ['감자탕/NNP', '전골/NNP'], ['감자탕/NNP', '콩나물/NNP', '더하/VV', '국물/NNG', '시원/XR'], ['특별/XR', '김치/NNP', '해장국/NNP', '마련/NNG'], ['메뉴/NNP', '뼈/NNG', '해장국/NNP'], ['김치/NNP', '해장국/NNP', '사용/NNG', '국물/NNG', '시원/XR'], ['콩나물/NNP', '들어가/VV'], ['주문/NNP', '콩나물/NNP'], ['벌/NNG', '떼/NNG', '해장국/NNP', '메뉴/NNP', '콩나물/NNP', '황태/NNP', '해장국/NNP', '이다/NNP'], ['황태/NNP', '벌/NNG', '떼/NNG', '해장국/NNP', '가격/NNG', '손님/NNG', '제공/NNG'], ['황태/NNP', '위하/VV', '사용/NNG', '주문/NNP'], ['벌/NNG', '떼/NNG', '해장국/NNP', '처음/NNG', '시작/NNG'], ['당시/NNG', '남편/NNG', '대표/NNG', '운영/NNG'], ['해장국/NNP', '대표/NNG', '운영/NNG'], ['아들/NNG', '아내/NNG', '대표/NNG', '당시/NNG', '운영/NNG'], ['남편/NNG', '대표/NNG', '식당/NNP', '운영/NNG', '식당/NNP', '아내/NNG', '식당/NNP', '운영/NNG', '시작/NNG'], [], ['대표/NNG', '처음/NNG', '식당/NNG', '운영/NNG'], ['아내/NNG', '남편/NNG', '아들/NNG', '식당/NNG', '김치/NNP'], ['동안/NNG', '식당/NNP', '위치/NNG', '정도/NNG'], ['손님/NNG', '정도/NNG'], ['제공/NNG', '벌/NNG', '떼/NNG', '해장국/NNP'], ['메뉴/NNP', '뼈/NNG', '해장국/NNP', '뼈다귀/NNG', '감자탕/NNP', '콩나물/NNP', '황태/NNP', '해장국/NNP', '김치/NNP', '해장국/NNP', '뼈다귀/NNG', '전골/NNP'], ['위치/NNG'], ['야간/NNG']]\n",
      "[['당진/NNP', '지역/NNP', '휘발유/NNP', '가격/NNG', '경유/NNP', '가격/NNG', '상승/NNG'], ['기준/NNG', '당진/NNP', '지역/NNP', '평균/NNG', '휘발유/NNP', '가격/NNG', '경유/NNP', '반면/NNG', '기준/NNG', '휘발유/NNP', '경유/NNP'], ['따르/VV', '최근/NNG', '송악읍/NNP', '휘발유/NNP', '경유/NNP', '평균/NNG', '가격/NNG', '당진/NNP', '지역/NNP', '나타나/VV'], ['반면/NNG', '휘발유/NNP', '평균/NNG', '가격/NNG', '경유/NNP', '평균/NNG', '가격/NNG', '저렴/XR'], ['휘발유/NNP', '평균/NNG', '가격/NNG', '충남/NNP', '휘발유/NNP', '평균/NNG', '가격/NNG', '정도/NNG'], ['경유/NNP', '평균/NNG', '가격/NNG', '충남/NNP', '평균/NNG', '정도/NNG', '나타나/VV'], ['주유소/NNP', '유류/NNG', '가격/NNG', '송악읍/NNP', '휘발유/NNP', '경유/NNP', '주유소/NNP'], ['송악읍/NNP', '주유소/NNP', '휘발유/NNP', '가격/NNG', '경유/NNP', '가격/NNG', '저렴/XR', '나타나/VV'], ['유류/NNG', '가격/NNG', '주유소/NNP', '주유소/NNP', '유류/NNG', '판매/NNP', '가격/NNP'], ['가격/NNG', '저렴/XR'], ['당진/NNP', '주유소/NNP', '대표/NNG', '따르/VV', '국제/NNG', '유가/NNP', '상승/NNG', '따르/VV', '유가/NNP', '상승/NNG'], ['주유소/NNP', '대표/NNG', '국제/NNG', '유가/NNP', '가격/NNP', '주유소/NNP', '판매/NNP', '가격/NNP', '상승/NNG', '최근/NNG', '유가/NNP', '상승/NNG']]\n",
      "[['어기/VV', '천연가스/NNG', '안정/NNG', '수급/NNG', '위하/VV', '년/NNB', '기지/NNP', '건설/NNG', '차질/NNG', '진행/NNG', '강조/NNG'], ['의원/NNG', '천연가스/NNG', '장기/NNG', '수급/NNG', '전망/NNG', '수급/NNG', '안정/NNG', '제고/NNG', '위하/VV', '정책/NNG', '간담회/NNG', '가스/NNP', '에너지경제연구원/NNP', '천연가스/NNG', '공급/NNG', '대하/VV'], ['어기/VV', '의원/NNG', '석탄/NNP', '화력/NNP', '발전/NNP', '가스/NNP', '문제/NNG', '원전/NNG', '문제/NNG', '만큼/NNB', '가스/NNP', '발전/NNP'], ['석탄/NNP', '화력/NNP', '발전/NNP', '원전/NNG', '정부/NNG', '정책/NNG', '만큼/NNB', '천연가스/NNG', '안정/NNG', '수급/NNG', '위하/VV', '정부/NNG', '정책/NNG', '강조/NNG'], ['간담회/NNG', '수급/NNG', '관리/NNG', '년/NNB', '천연가스/NNG', '공급/NNG', '년/NNB', '수요/NNG', '증가/NNG', '년/NNB', '하락/NNG', '따르/VV', '하락/NNG', '발전/NNP', '증가/NNG', '수요/NNG', '증가/NNG', '수급/NNG', '계획/NNG', '따르/VV', '천연가스/NNG', '수요/NNG', '전망/NNG', '발표/NNG'], ['발표/NNG', '에너지경제연구원/NNP', '연구/NNG', '수급/NNG', '공급/NNG', '차질/NNG', '위하/VV', '저장/NNG', '기지/NNP', '건설/NNG', '정책/NNG', '연구/NNG', '발표/NNG'], ['대하/VV', '어기/VV', '의원/NNG', '장기/NNG', '천연가스/NNG', '수급/NNG', '계획/NNG', '기지/NNP', '년/NNB', '건설/NNG', '저장/NNG', '천연가스/NNG', '수급/NNG', '안정/NNG', '제고/NNG', '수급/NNG', '관리/NNG', '위하/VV', '기지/NNP', '건설/NNG', '계획/NNG', '차질/NNG', '진행/NNG']]\n",
      "[['당진시/NNP', '자문/NNP', '위원회/NNP', '비판/NNG', '있/VV'], ['당진시/NNP', '정책/NNG', '의견/NNG', '수렴/NNG', '정책/NNG', '자문/NNP', '위원회/NNP', '있/VV', '지적/NNG'], ['정책/NNG', '자문/NNP', '위원회/NNP', '분과/NNG', '위원/NNG', '참여/NNG', '있/VV'], ['정책/NNG', '자문/NNP', '위원회/NNP', '전체/NNG', '있/VV', '위원/NNG', '의견/NNG', '반영/NNG', '있/VV'], ['정책/NNG', '자문/NNP', '위원/NNP', '있/VV', '전체/NNG', '회의/NNG', '회의/NNG', '시간/NNG', '위원/NNG', '의견/NNG', '전달/NNG', '필요/NNG', '정책/NNG', '대하/VV', '자문/NNG', '형식/NNG', '의견/NNG', '수렴/NNG', '불과/XR', '비판/NNG'], ['분과/NNG', '회의/NNG', '개최/NNG'], ['위원/NNG', '위원/NNG', '의견/NNG', '반영/NNG', '있/VV', '위원/NNG', '결과/NNG'], ['회의/NNG', '전달/NNG', '시간/NNG', '정책/NNG', '자문/NNP', '필요/NNG', '구성/NNG', '위원회/NNG', '형식/NNG', '불과/XR'], ['정책/NNG', '자문/NNP', '위원/NNP', '위원/NNG', '회의/NNG', '참여/NNG', '있/VV', '위원/NNG', '대하/VV', '지적/NNG'], ['위원/NNG', '의견/NNG', '있/VV', '위원회/NNG', '구성/NNG'], ['당진시/NNP', '전체/NNG', '회의/NNG', '분과/NNG', '회의/NNG', '개최/NNG', '의견/NNG', '대하/VV', '자문/NNG', '정책/NNG', '자문/NNP', '위원회/NNG', '회의/NNG', '결과/NNG', '당진시/NNP', '위원/NNG']]\n",
      "[['마을/NNG', '법인/NNP', '운영/NNG', '관련/NNG', '교/NNG', '리/NNB', '이장/NNP', '대하/VV', '검찰/NNG', '업무/NNG', '상배/NNG', '기소/NNP', '중지/NNG', '처분/NNG', '내리/VV', '형사/NNP', '조정/NNP', '위원회/NNP', '회부/NNG'], ['교/NNG', '리/NNB', '마을/NNG', '법인/NNP', '교/NNG', '운영/NNG', '관련/NNG', '이장/NNP', '마을/NNG', '모래/NNP', '관련/NNG', '지급/NNG', '과정/NNG', '모래/NNP', '지급/NNG', '지난해/NNG'], ['마을/NNG', '법인/NNP', '교/NNG', '리/NNB', '법인/NNP', '관련/NNG', '매입/NNG', '과정/NNG', '매입/NNG', '마을/NNG', '법인/NNP'], ['관련/NNG', '교/NNG', '리/NNB', '마을/NNG', '법인/NNP', '운영/NNG'], ['검찰/NNG', '대하/VV', '지난해/NNG', '업무/NNG', '상배/NNG', '기소/NNP', '중지/NNG', '처분/NNG', '내리/VV', '형사/NNP', '조정/NNP', '위원회/NNP', '회부/NNG'], ['형사/NNP', '조정/NNP', '마을/NNG', '법인/NNP', '대하/VV', '밝히/VV', '밝히/VV'], ['형사/NNP', '조정/NNP'], ['이장/NNP', '지난해/NNG', '교/NNG', '리/NNB', '이장/NNP'], ['교/NNG', '리/NNB', '이장/NNP', '이장/NNP', '밝히/VV']]\n",
      "[['방송통신대학/NNP', '당진/NNP', '학생회/NNG', '취임식/NNG', '지나/VV', '설렁탕/NNP', '열리/VV'], ['방송통신대학/NNP', '당진/NNP', '학생회/NNG', '취임식/NNG', '영호/NNP', '회장/NNG', '강연/NNG', '회장/NNG', '취임/NNG'], ['취임식/NNG', '지나/VV', '설렁탕/NNP', '열리/VV'], ['취임식/NNG', '공로상/NNG', '학생회/NNG', '전달/NNG', '장학금/NNP'], ['장학금/NNP', '학생/NNG', '전달/NNG', '공로상/NNG', '영호/NNP', '직전/NNP', '회장/NNG', '김은선/NNP', '직전/NNP', '수석/NNP', '부회장/NNP', '국장/NNP', '박성현/NNP', '국장/NNP', '국장/NNP'], ['영호/NNP', '회장/NNG', '열리/VV', '학생/NNG', '올해/NNG', '당진/NNP', '학생회/NNG', '말/NNG'], [], ['회장/NNG', '강연/NNG', '수석/NNP', '부회장/NNP', '부회장/NNP', '박성현/NNP', '김은선/NNP'], ['강연/NNG', '취임/NNG'], ['탈락/NNG', '학우/NNG'], ['방송통신대학/NNP', '당진/NNP', '학생회장/NNG', '취임/NNG', '강연/NNG', '회장/NNG', '당진/NNP', '학생회/NNG', '학생회장/NNG', '당진/NNP', '학생회/NNG', '학우/NNG', '말/NNG'], ['회장/NNG', '올해/NNG', '탈락/NNG', '학우/NNG', '학생회/NNG', '말/NNG'], ['정리/NNG', '정리/NNG', '말/NNG'], ['정리/NNG', '말/NNG'], ['올해/NNG', '학생회/NNG']]\n",
      "[['한국생활음악협회/NNP', '당진/NNP', '지부/NNG', '한국생활음악협회/NNP', '당진/NNP', '지부/NNG', '새롭/VA', '지부장/NNG', '김형태/NNP', '지부장/NNG', '선출/NNG'], ['지부장/NNG', '이임/NNG'], ['열리/VV', '사업/NNG', '사업/NNG'], ['회원/NNG', '동안/NNG', '한국생활음악협회/NNP', '당진/NNP', '지부/NNG', '이끌/VV', '신임/NNP', '지부장/NNG', '김형태/NNP', '지부장/NNG', '선출/NNG'], ['이임/NNG', '지부장/NNG', '지부장/NNG', '동안/NNG', '회원/NNG', '새롭/VA'], ['한국생활음악협회/NNP', '당진/NNP', '지부/NNG', '열리/VV', '음악회/NNG', '소외/NNP', '소외/NNP', '공연/NNG', '음악회/NNG'], ['지부장/NNG', '김형태/NNP', '공연/NNG'], ['김형태/NNP', '신임/NNP', '지부장/NNG', '지역민/NNG'], ['새롭/VA', '이끌/VV', '김형태/NNP', '지부장/NNG', '창립/NNG', '회원/NNG', '올해/NNG', '창립/NNG'], ['올해/NNG', '사업/NNG', '지역민/NNG']]\n",
      "[['지나/VV', '당진/NNP', '교육/NNP', '지원/NNP', '예비/NNP', '중학생/NNG', '부모/NNG', '학부모/NNG', '교육/NNG', '진행/NNG'], ['중학교/NNP', '예비/NNP', '학부모/NNG', '교육/NNG', '지나/VV', '당진/NNP', '교육/NNP', '지원/NNP'], ['교육/NNG', '중학교/NNP', '예비/NNP', '학부모/NNG', '중학교/NNP', '생활/NNG', '자유/NNG', '학기/NNG', '안내/NNG', '진행/NNG'], ['학부모/NNG', '교육/NNG', '중학교/NNP', '생활/NNG', '학부모/NNG', '자유/NNG', '학기/NNG', '안내/NNG', '진행/NNG'], ['안전/NNG', '안전/NNG', '대하/VV'], ['한편/NNG', '당진/NNP', '교육/NNP', '지원/NNP', '학부모/NNG', '교육/NNG', '학부모/NNG', '교육/NNG', '학부모/NNG', '자녀/NNG', '교육/NNG', '학부모/NNG', '계획/NNG'], [], ['중학생/NNG', '되/VV'], ['변하/VV'], ['학부모/NNG', '대로/NNB', '자녀/NNG', '강요/NNG'], ['학교/NNG', '변화/NNG', '학부모/NNG', '변하/VV', '하/VV'], ['아이들/NNP', '하/VV'], ['부모/NNG', '아이/NNG', '사춘기/NNP'], ['자신/NNG', '생각/NNG'], ['사춘기/NNP', '하/VV'], ['자녀/NNG', '변화/NNG', '하/VV'], ['부모/NNG', '아이/NNG', '변화/NNG', '부모/NNG', '하/VV', '대로/NNB', '강요/NNG', '자신/NNG', '자녀/NNG', '행동/NNG', '변화/NNG', '수/NNB', '있/VV', '여기/VV', '되/VV'], ['생각/NNG', '부모/NNG', '자녀/NNG', '생기/VV'], ['생기/VV', '자녀/NNG', '성장/NNG', '과정/NNG', '이해/NNG', '하/VV'], [], ['한편/NNG', '중학생/NNG', '되/VV', '환경/NNG', '되/VV'], ['교사/NNG', '되/VV'], ['교사/NNG', '수/NNB'], ['부모/NNG', '하/VV', '수/NNB', '있/VV'], ['교사/NNG', '자녀/NNG', '부당/XR', '행동/NNG', '하/VV', '학교/NNG', '연락/NNG', '하/VV'], ['자녀/NNG', '교사/NNG', '나서/VV', '부당/XR', '연락/NNG', '학부모/NNG', '있/VV'], ['환경/NNG', '교육/NNG', '부모/NNG', '교육/NNG', '환경/NNG', '나서/VV', '바라/VV'], ['자녀/NNG', '세대/NNG'], ['하/VV'], ['자유/NNG', '여기/VV'], ['나서/VV', '하/VV', '정도/NNG'], ['하/VV', '세대/NNG'], ['아이들/NNP', '세대/NNG', '이해/NNG', '바라/VV'], ['한편/NNG', '중학교/NNG', '수행평가/NNP'], ['수행/NNG', '과제/NNG', '수행/NNG', '과정/NNG', '대하/VV', '평가/NNG', '평가/NNG', '평가/NNG'], ['평가/NNG', '수행평가/NNP', '계획/NNG'], ['부모/NNG', '아이들/NNP', '과제/NNG', '수행/NNG', '평가/NNG', '하/VV', '주시/NNP', '바라/VV'], ['부모/NNG', '과제/NNG', '자녀/NNG', '정도/NNG', '문제/NNG', '중학교/NNG', '수/NNB', '있/VV'], ['아이/NNG', '성장/NNG', '수/NNB', '있/VV', '문제/NNG', '수/NNB', '있/VV', '학부모/NNG', '주시/NNP', '바라/VV']]\n",
      "[['품질/NNP', '안전/NNP', '농/NNG', '식품/NNG', '농업/NNG', '지원/NNG', '위하/VV', '다양/XR'], ['농/NNG', '관원/NNG', '그동안/NNG', '친환경/NNP', '인증/NNP', '식품/NNG', '인증/NNP', '다양/XR', '농/NNG', '식품/NNG', '인증/NNP', '관리/NNP', '원산지/NNG', '표시/NNG', '관리/NNG', '농산물/NNG', '검사/NNP', '농/NNG', '식품/NNG', '품질/NNP', '관리/NNG', '실시/NNG'], ['유통/NNG', '역할/NNG', '있/VV'], ['국중/NNG', '당진/NNP', '소장/NNP', '취임/NNG'], ['담양군/NNP', '출신/NNG', '국/NNG', '소장/NNP', '호남대학교/NNP', '학과/NNP', '서울시립대학교/NNP', '과학기술/NNP', '대학원/NNP', '환경/NNG', '원예/NNP', '학과/NNP', '졸업/NNG'], ['농/NNG', '관원/NNG', '경북/NNP', '지원/NNP', '운영/NNG', '지원/NNG', '광양/NNP', '사무소장/NNG', '지나/VV', '당진/NNP', '사무소장/NNG', '취임/NNG'], ['국/NNG', '소장/NNP', '농산물/NNG', '안전/NNG', '관리/NNG', '위하/VV', '당진/NNP', '하/VV', '농가/NNP', '확대/NNG', '것/NNB', '그동안/NNG'], ['국/NNG', '소장/NNP', '지나/VV', '당진/NNP', '인증/NNP', '농가/NNP', '농가/NNP', '지난해/NNG', '농가/NNP', '인증/NNP', '당진/NNP', '인증/NNP', '농가/NNP', '농가/NNP'], ['당진/NNP', '품목/NNG', '품목/NNG', '확대/NNG', '올해/NNG', '농가/NNP', '확대/NNG', '인증/NNP', '실시/NNG', '것/NNB'], ['지난해/NNG', '당진/NNP', '적발/NNG', '원산지/NNG', '품목/NNG', '부정/NNP', '유통/NNP', '국산품/NNG', '농가/NNP', '원산지/NNG', '표시/NNG', '적발/NNG', '농가/NNP'], ['대하/VV', '국/NNG', '소장/NNP', '농산물/NNG', '생산/NNG', '유통/NNG', '농가/NNP', '대하/VV', '안전/NNP', '관리/NNP', '원산지/NNG', '단속/NNG', '집중/NNG', '올해/NNG', '쌀/NNG', '더불/VV', '단속/NNG', '품목/NNG', '확대/NNG', '부정/NNP', '유통/NNP', '단속/NNG', '확대/NNG', '것/NNB'], ['국/NNG', '소장/NNP', '더불/VV', '쌀/NNG', '확대/NNG', '것/NNB', '농산물/NNG', '국산품/NNG', '있/VV'], ['품질/NNP', '친환경/NNP', '있/VV', '당진시/NNP', '수도/NNG', '중심/NNG', '수확/NNP', '품종/NNP', '있/VV', '것/NNB', '대하/VV'], ['국/NNG', '소장/NNP', '품질/NNP', '안전/NNG', '농산물/NNG', '친환경/NNP', '농산물/NNG', '생산/NNG', '하/VV', '수도/NNG', '중심/NNG', '품질/NNP', '쌀/NNG', '생산/NNG', '집중/NNG', '수확/NNP', '품목/NNG', '확대/NNG', '하/VV'], ['있/VV', '나루/NNP', '쌀/NNG', '대하/VV', '관리/NNG', '나루/NNP', '쌀/NNG', '더불/VV', '특색/NNG', '살리/VV', '하/VV'], ['위하/VV', '당진시/NNP', '다양/XR', '품종/NNP', '있/VV', '협력/NNG', '하/VV', '것/NNB'], ['역할/NNG'], ['방법/NNG', '대하/VV', '고민/NNG', '당진시/NNP', '특색/NNG', '살리/VV', '품목/NNG', '집중/NNG', '수출/NNG', '개척/NNG', '하/VV'], ['당진/NNP', '농업/NNG', '하/VV'], ['당진시/NNP', '농업/NNG', '협력/NNG', '당진/NNP', '농업/NNG', '개척/NNG', '하/VV'], ['방법/NNG', '농산물/NNG', '다양/XR', '수출/NNG', '하/VV', '있/VV', '방법/NNG', '고민/NNG', '것/NNB'], ['국중/NNG', '소장/NNP'], ['담양군/NNP', '출신/NNG'], ['호남대학교/NNP', '졸업/NNG'], ['서울시립대학교/NNP', '과학기술/NNP', '대학원/NNP'], ['환경/NNG', '원예/NNP', '학과/NNP', '졸업/NNG'], ['국립/NNP', '농/NNG', '관원/NNG', '품질/NNP', '검사/NNP'], ['국립/NNP', '농/NNG', '관원/NNG', '경북/NNP', '지원/NNP', '운영/NNG', '지원/NNG'], [], ['광양/NNP', '사무소장/NNG'], ['국립/NNP', '농/NNG', '관원/NNG', '지원/NNP', '당진/NNP', '사무소장/NNG']]\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "with open(input_file_name, 'r', encoding = 'utf-8', newline = '') as input_file:\n",
    "    i = 0\n",
    "    for line in input_file:\n",
    "        line = json.loads(line)\n",
    "        id_num, sents = list(line.values())[1:]\n",
    "        preprocessed = [ preprocess_sentence(sent) for sent in sents ]\n",
    "        key_index = textrank_keysentence(preprocessed , komoran_tokenize , 2 , 0.1 , cosine_sent_sim )\n",
    "        key_sentence1 ='\\n'.join([sents[t] for t in key_index])      \n",
    "        i += 1\n",
    "        if i == 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-282ccfbf7dc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mid_num\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mpreprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0mpreprocess_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msents\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mkey_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtextrank_keysentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mkomoran_tokenize\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtextrank_sent_sim\u001b[0m   \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mkey_sentence1\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkey_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mrow1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mid_num\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mkey_sentence1\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-a19b4b6d9660>\u001b[0m in \u001b[0;36mtextrank_keysentence\u001b[1;34m(sents, tokenize, min_count, min_sim, similarity, df, max_iter, topk)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msent_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0msimilarity\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mmin_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_sim\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpagerank\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0midxs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margsort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtopk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mkey_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midxs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#     keysents = [(idx, R[idx], sents[idx]) for idx in reversed(idxs)]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# try 5\n",
    "with open(input_file_name, 'r', encoding = 'utf-8', newline = '') as input_file:\n",
    "    i = 0\n",
    "    for line in input_file:\n",
    "        line = json.loads(line)\n",
    "        id_num, sents = list(line.values())[1:]\n",
    "        preprocessed = [ preprocess_sentence(sent) for sent in sents ]\n",
    "        key_index = textrank_keysentence(preprocessed , komoran_tokenize , 2 , 0.1 , textrank_sent_sim   )\n",
    "        key_sentence1 ='\\n'.join([sents[t] for t in key_index])\n",
    "        row1 = [id_num , key_sentence1 ]\n",
    "        submission2.loc[i] = row1\n",
    "        i +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission2.to_csv('C:/Users/Playdata/Desktop/dacon_extract_summary/extractive_submission2.csv', sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
