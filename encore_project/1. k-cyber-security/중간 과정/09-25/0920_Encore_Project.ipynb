{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from itertools import islice\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "\n",
    "# plt.show()시 한글 폰트 깨지는거 방지\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(r'C:/Users/Playdata/pytest/MainProject/\\sample.csv', encoding='utf-8')\n",
    "data = csv.reader(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv 파일에서부터 각각의 그래프를 만드는데 필요한 변수들을 모아 리턴합니다. \n",
    "def len_like_bag_ngram(comment_data) :\n",
    "    len_list = []\n",
    "    like_list = []\n",
    "    word_bag = []\n",
    "    Ngram =[]\n",
    "    count = 0\n",
    "    for i in comment_data:\n",
    "        if count ==0:\n",
    "            count =1\n",
    "            continue\n",
    "        temp = re.findall(r'\\w+', i[2]) #특수문자를 제외한 글자들만 뽑아 리스트 형태로 저장함\n",
    "        word_bag +=temp\n",
    "        len_list.append(len(temp))\n",
    "        like_list.append(int(i[3]))\n",
    "        Ngram += [temp[i] +' '+temp[i+1] for i in range(len(temp)-1)]\n",
    "                         \n",
    "    return len_list, like_list , word_bag , Ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_word_bag(comment_data):\n",
    "#     word_bag = []\n",
    "#     for i in comment_data:\n",
    "#         word_bag +=re.findall(r'\\w+', i[2])\n",
    "#     return word_bag\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 댓글별 단어수의 분포도\n",
    "def len_distribution(len_list):\n",
    "    plt.xlim([min(len_list)-5, max(len_list)+5])\n",
    "    plt.hist(len_list, alpha=0.5, bins=10)\n",
    "    plt.title(\"Length distribution of comments\")\n",
    "    plt.xlabel('Comment_length')\n",
    "    plt.ylabel('count')\n",
    "    plt.savefig('len_distribution.png', dpi=300)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 댓글별 좋아요수의 분포도\n",
    "def like_distribution(like_list):\n",
    "    plt.xlim([min(like_list)-5, max(like_list)+5])\n",
    "    plt.hist(like_list, alpha=0.5)\n",
    "    plt.title(\"Like distribution of comments\")\n",
    "    plt.xlabel('Like')\n",
    "    plt.ylabel('count')\n",
    "    plt.savefig('like_distribution.png', dpi=300)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어의 출현 빈도수\n",
    "def word_frequency(bag):\n",
    "    freq_word = Counter(bag)\n",
    "    top_30 = list(islice(sorted(freq_word.items(),key=lambda x: (-x[1], x[0])), 30))\n",
    "    labels, values = zip(*top_30)\n",
    "    indexes = np.arange(len(labels))\n",
    "    width = 1\n",
    "    plt.bar(indexes, values, width, alpha=0.5)\n",
    "    plt.xticks(indexes + width * 0.5, labels, rotation=75)\n",
    "    plt.savefig('word_frequency.png', dpi=300)\n",
    "    plt.clf()\n",
    "# OrderedDict([('의사', 21), ('응원합니다', 19), ('의사가', 18), ('의사들이', 14), ('지방에', 11)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 복합 명사의 출현 횟수를 보여주는 그래프\n",
    "def ngram_frequency(bag):\n",
    "    freq_word = Counter(bag)\n",
    "    top_15 = list(islice(sorted(freq_word.items(),key=lambda x: (-x[1], x[0])), 15)) # 갯수가 상위 15개인것만 추림\n",
    "    labels, values = zip(*top_15)\n",
    "    indexes = np.arange(len(labels))\n",
    "    width = 1\n",
    "    plt.bar(indexes, values, width, alpha=0.5)\n",
    "    plt.xticks(indexes + width * 0.5, labels, rotation=75)\n",
    "    plt.savefig('ngram_frequency.png', dpi=300)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "len_list , like_list , word_bag , Ngram = len_like_bag_ngram(data)\n",
    "len_distribution(len_list)\n",
    "like_distribution(like_list)\n",
    "word_frequency(word_bag)\n",
    "ngram_frequency(Ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
